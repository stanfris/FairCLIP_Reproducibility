#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=9
#SBATCH --gpus=1
#SBATCH --job-name=linearprobeCLIP_base
#SBATCH --ntasks=1
#SBATCH --time=01:00:00
#SBATCH --mem=32000M
#SBATCH --output=linear_probe_test_base_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2

# Activate your environment
source activate fairclip

OMP_NUM_THREADS=1 

# directories
DATA_DIR=../data/Harvard-FairVLMed
PRETRAIN_CHKPT=../results/glaucoma_CLIP_vit-l14_seed1542_auc0.6424/clip_ep002.pth
PRETRAIN_CHKPT=ViT-L/14
EXP_NAME=tmp_linprobe

# hyperparameters
CFG_PATH=../LAVIS/lavis/projects/blip2/train/pretrain_stage1.yaml
FEATS_TYPE=image # [image, multimodal]
MODEL_TYPE=clip # [clip, blip2]
SUMMARY_TYPE=gpt-4
BATCH_SIZE=512
EPOCHS=100
LR=0.1
WDECAY=0.0

# Run your code
cd ../mae
srun python3 main_linprobe.py \
            --model_type ${MODEL_TYPE} \
            --vl_feats_type ${FEATS_TYPE} \
            --vision_encoder_weights clip \
            --summary_type ${SUMMARY_TYPE} \
            --batch_size ${BATCH_SIZE} \
            --model vit_large_patch16 \
            --cls_token \
	    --finetune ${PRETRAIN_CHKPT} \
            --epochs ${EPOCHS} \
            --blr ${LR} \
            --weight_decay ${WDECAY} \
            --data_path ${DATA_DIR} \
            --output_dir ${EXP_NAME} \
            --log_dir ${EXP_NAME} \
            --nb_classes 2 \
            --blip_feats_select avgpool \
            --cfg-path ${CFG_PATH}
