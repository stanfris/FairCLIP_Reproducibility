#!/bin/bash

#SBATCH --partition=gpu_mig
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=9
#SBATCH --gpus=1
#SBATCH --job-name=linearprobeCLIP
#SBATCH --ntasks=1
#SBATCH --time=00:30:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2023
module load Anaconda3/2023.07-2

# Activate your environment
source activate fairclip
pip install openai-clip

OMP_NUM_THREADS=1 

# directories
DATA_DIR=/Path/to/FairVLMed
PRETRAIN_CHKPT=/Path/to/CKPT
EXP_NAME=tmp

# hyperparameters
CFG_PATH=../LAVIS/lavis/projects/blip2/train/pretrain_stage1.yaml
FEATS_TYPE=image # [image, multimodal]
MODEL_TYPE=clip # [clip, blip2]
SUMMARY_TYPE=gpt-4
BATCH_SIZE=512
EPOCHS=1000
BLR=0.1 # learning rate
WDECAY=0.0

# Run your code
cd ../mae
srun python3 main_linprobe.py \
            --model_type ${MODEL_TYPE} \
            --vl_feats_type ${FEATS_TYPE} \
            --vision_encoder_weights clip \
            --summary_type ${SUMMARY_TYPE} \
            --batch_size ${BATCH_SIZE} \
            --model vit_large_patch16 \
            --cls_token \
            --finetune ${PRETRAIN_CHKPT} \
            --epochs ${EPOCHS} \
            --blr ${BLR} \
            --weight_decay ${WDECAY} \
            --data_path ${DATA_DIR} \
            --output_dir $EXP_NAME \
            --log_dir $EXP_NAME \
            --nb_classes 2 \
            --blip_feats_select avgpool \
            --cfg-path ${CFG_PATH}
